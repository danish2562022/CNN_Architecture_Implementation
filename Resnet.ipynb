{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fe7679d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "85ec6baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_channels,intermediate_channels,identity_downsample=None,stride=1):\n",
    "        super(block,self).__init__()\n",
    "        self.expansion=4\n",
    "        self.conv1=nn.Conv2d(in_channels,intermediate_channels,kernel_size=1,stride=1,padding=0,bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv2=nn.Conv2d(intermediate_channels,intermediate_channels,kernel_size=3,stride=stride,padding=1,bias=False)\n",
    "        self.bn2=nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv3=nn.Conv2d(intermediate_channels,intermediate_channels*self.expansion,kernel_size=1,stride=1,padding=0,bias=False)\n",
    "        self.bn3=nn.BatchNorm2d(intermediate_channels*self.expansion)\n",
    "        \n",
    "        self.identity_downsample=identity_downsample\n",
    "        self.relu=nn.ReLU()\n",
    "        self.stride=stride \n",
    "        \n",
    "    def forward(self,x):\n",
    "        identity=x\n",
    "        x=self.conv1(x)\n",
    "        x=self.bn1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.bn2(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.conv3(x)\n",
    "        x=self.bn3(x)\n",
    "        \n",
    "        if self.identity_downsample is not None:\n",
    "            identity=self.identity_downsample(identity)\n",
    "            \n",
    "        x+=identity\n",
    "        x=self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c3c65053",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module): #[3,4,6,3]\n",
    "    \n",
    "    def __init__(self,block,layers,image_channels,num_classes):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.in_channels=64\n",
    "        self.conv1=nn.Conv2d(image_channels,64,kernel_size=7,stride=2,padding=3,bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(64)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "        \n",
    "        self.layer1=self._make_layer(block,layers[0],intermediate_channels=64,stride=1)\n",
    "        self.layer2=self._make_layer(block,layers[1],intermediate_channels=128,stride=2)\n",
    "        self.layer3=self._make_layer(block,layers[2],intermediate_channels=256,stride=2)\n",
    "        self.layer4=self._make_layer(block,layers[3],intermediate_channels=512,stride=2)\n",
    "        \n",
    "        self.avgpool=nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc=nn.Linear(512*4,num_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.bn1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "        \n",
    "        x=self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        x=self.layer3(x)\n",
    "        x=self.layer4(x)\n",
    "        \n",
    "        x=self.avgpool(x)\n",
    "        x=x.reshape(x.shape[0],-1)\n",
    "        x=self.fc(x)\n",
    "        return x \n",
    "        \n",
    "    def _make_layer(self,block,num_residual_blocks,intermediate_channels,stride):\n",
    "        identity_downsample=None\n",
    "        layers=[]\n",
    "        \n",
    "        if stride!=1 or self.in_channels!=intermediate_channels*4:\n",
    "            \n",
    "            identity_downsample=nn.Sequential(nn.Conv2d(self.in_channels,intermediate_channels*4,kernel_size=1,\n",
    "                                                        stride=stride),nn.BatchNorm2d(intermediate_channels*4))\n",
    "            \n",
    "        layers.append(block(self.in_channels,intermediate_channels,identity_downsample,stride))\n",
    "        self.in_channels=intermediate_channels*4\n",
    "        \n",
    "        for i in range(num_residual_blocks-1):\n",
    "            layers.append(block(self.in_channels,intermediate_channels))\n",
    "            \n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1fe9259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(img_channels=3,num_classes=1000):\n",
    "    \n",
    "    return ResNet(block,[3,4,6,3],img_channels,num_classes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "17955a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    net=ResNet50()\n",
    "    x=torch.randn(2,3,224,224)\n",
    "    y=net(x)\n",
    "    return(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "30339459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1000])\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    net = ResNet50(img_channels=3, num_classes=1000)\n",
    "    y = net(torch.randn(4, 3, 224, 224)).to(\"cuda\")\n",
    "    print(y.size())\n",
    "\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dc672cb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-9063a9f0e032>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c193048d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1000])\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "From scratch implementation of the famous ResNet models.\n",
    "The intuition for ResNet is simple and clear, but to code\n",
    "it didn't feel super clear at first, even when reading Pytorch own\n",
    "implementation. \n",
    "Video explanation: \n",
    "Got any questions leave a comment on youtube :)\n",
    "Programmed by Aladdin Persson <aladdin.persson at hotmail dot com>\n",
    "*    2020-04-12 Initial coding\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class block(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, intermediate_channels, identity_downsample=None, stride=1\n",
    "    ):\n",
    "        super(block, self).__init__()\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, intermediate_channels, kernel_size=1, stride=1, padding=0, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            intermediate_channels,\n",
    "            intermediate_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            intermediate_channels,\n",
    "            intermediate_channels * self.expansion,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, image_channels, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Essentially the entire ResNet architecture are in these 4 lines below\n",
    "        self.layer1 = self._make_layer(\n",
    "            block, layers[0], intermediate_channels=64, stride=1\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block, layers[1], intermediate_channels=128, stride=2\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block, layers[2], intermediate_channels=256, stride=2\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block, layers[3], intermediate_channels=512, stride=2\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * 4, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n",
    "        # we need to adapt the Identity (skip connection) so it will be able to be added\n",
    "        # to the layer that's ahead\n",
    "        if stride != 1 or self.in_channels != intermediate_channels * 4:\n",
    "            identity_downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    self.in_channels,\n",
    "                    intermediate_channels * 4,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(intermediate_channels * 4),\n",
    "            )\n",
    "\n",
    "        layers.append(\n",
    "            block(self.in_channels, intermediate_channels, identity_downsample, stride)\n",
    "        )\n",
    "\n",
    "        # The expansion size is always 4 for ResNet 50,101,152\n",
    "        self.in_channels = intermediate_channels * 4\n",
    "\n",
    "        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
    "        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n",
    "        # and also same amount of channels.\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(block(self.in_channels, intermediate_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def ResNet50(img_channel=3, num_classes=1000):\n",
    "    return ResNet(block, [3, 4, 6, 3], img_channel, num_classes)\n",
    "\n",
    "\n",
    "def ResNet101(img_channel=3, num_classes=1000):\n",
    "    return ResNet(block, [3, 4, 23, 3], img_channel, num_classes)\n",
    "\n",
    "\n",
    "def ResNet152(img_channel=3, num_classes=1000):\n",
    "    return ResNet(block, [3, 8, 36, 3], img_channel, num_classes)\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = ResNet101(img_channel=3, num_classes=1000)\n",
    "    y = net(torch.randn(4, 3, 224, 224)).to(\"cuda\")\n",
    "    print(y.size())\n",
    "\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0b87b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
